### LLM(Large Language Model)의 토큰 처리 방법
- LLM이 한 번에 처리 할 수 있는 최대 토큰의 수는 모델이 발전 함에 따라 증가하고 있지만, 태생적으로 그 한계가 정해져 있으며 이를 극복하기 위해 다음과 같은 방법들을 사용하고 있음
  (최대 토큰 수는 입력 프롬프트와 생성되는 응답을 합친 값)
	- **Stuffing**
		- "채우기"라는 뜻 그대로 아무 것도 바꾸지 않고 있는 그대로 프롬프트를 적용
		- 가장 직관적이며 한 번의 API만 요청하는 장정이 있지만, 쉽게 토근 한도에 도달해 오류가 발생할 확률이 높다는 단점이 있음
	- **Map Reduce**
		- 사용자의 입력 또는 문서를 n개로 나누어 총 n개의 (프롬프트 + 입력조각)세트를 만들어 각각 API 요청을 보냄
		- 각각의 요청은 독립적이며 병렬로 진행될 수 있음
		- 위의 단계를 통해 생성된 n개의 생성된 값을 한대 모아 다시 API 요청을 보내 최종 응답을 생성		  
		- 긴 입력 값을 처리가능한 장점이 있지만, 한 번의 동작에 많은 API를 요청하므로 비용이슈가 생길 수 있고, 쪼개진 입력을 매핑해서 처리하는 고정에서 정보의 손실이 발생하기 쉽다는 단점이 있음
	- **Refine**
		- 사용잡의 입력 또는 문서를 n개로 나누어 각각 요청을 보내는 것은 Map Reduce와 유사하지만, 첫번째 입력조각부터 순차적으로 요청을 보내며 첫번째 요청을 통해 생성된 응답값을 두번째 입력조각과 함께 API 요청을 보냄.
		- 위와 같은 방법으로 이전 입력 조각으로부터 생성된 응답값을 다음 입력조각과 함께 API 요청을 보내는 n번의 반복을 통해 최종 응답값을 생성
		- 정보 손실을 최소화 시키며 긴 입력에 대한 처리가 가능하다는 장점이 있지만, 모든 입력과 생성이 순차적으로 진행되어야 최종 응답 생성까지 상대적으로 오랜 시간이 걸린다는 단점이 있음