### LLM(Large Language Model)의 토큰 한계 및 극복 방안
- LLM이 한 번에 처리 할 수 있는 최대 토큰의 수는 모델이 발전 함에 따라 증가하고 있지만, 태생적으로 그 한계가 정해져 있음 (최대 토큰 수는 입력 프롬프트와 생성되는 응답을 합친 값)
- 특히 문서를 요약하고자 할 때 문서의 크기에 따라 입력값이 커지므로 토큰의 한계점 문제가 대두되며 이를 해결하기 위해 다음과 같은 방법들이 있음
	- **Stuffing**
		- "채우기"라는 뜻 그대로 아무 것도 바꾸지 않고 있는 그대로 프롬프트를 적용
		- 가장 직관적이며 한 번의 API만 요청하는 장정이 있지만, 쉽게 토근 한도에 도달해 오류가 발생할 확률이 높다는 단점이 있음
	- **Map Reduce**
		- 사용자의 입력 또는 문서를 n개로 나누어 총 n개의 (프롬프트 + 입력조각)세트를 만들어 각각 API 요청을 보냄
		- 각각의 요청은 독립적이며 병렬로 진행될 수 있음
		- 위의 단계를 통해 생성된 n개의 생성된 값을 한대 모아 다시 API 요청을 보내 최종 응답을 생성		  
		- 긴 입력 값을 처리가능한 장점이 있지만, 한 번의 동작에 많은 API를 요청하므로 비용이슈가 생길 수 있고, 쪼개진 입력을 매핑해서 처리하는 고정에서 정보의 손실이 발생하기 쉽다는 단점이 있음
	- **Refine**
		- 사용잡의 입력 또는 문서를 n개로 나누어 각각 요청을 보내는 것은 Map Reduce와 유사하지만, 첫번째 입력조각부터 순차적으로 요청을 보내며 첫번째 요청을 통해 생성된 응답값을 두번째 입력조각과 함께 API 요청을 보냄.
		- 위와 같은 방법으로 이전 입력 조각으로부터 생성된 응답값을 다음 입력조각과 함께 API 요청을 보내는 n번의 반복을 통해 최종 응답값을 생성
		- 정보 손실을 최소화 시키며 긴 입력에 대한 처리가 가능하다는 장점이 있지만, 모든 입력과 생성이 순차적으로 진행되어야 함으로 최종 응답 생성까지 상대적으로 오랜 시간이 걸린다는 단점이 있음

### LangChain에서 메모리 활용
- ChatLLM 모델을 활용해 이전 내용을 참조해 대화를 이어나가기 위해서는 대화 내역을 저장하고 그 내용을 API 요청시마다 함께 보내야 하며, 그 외에도 계산의 리소스가 크거나 자주 접근하는 값에 대해서는 메모리로 관리활 필요가 있음
- LangChain에서는 메모리 기능을 지원하며 체인 선언시 메모리를 인자로 전달해주면 체인이 API 요청에 필요한 값을 자동으로 채워서 사용함
- LangChain에서 지원하는 Memory의 종류
	- `ConversationBufferMemory` : 대화내역을 저장하기 위한 가장 기본적인 메모리 이며, 대화가 길어질 수록 버퍼의 크기 즉 LLM 모델에 요청할 입력의 크기가 커지므로 한 번에 처리 가능한 최대 토큰 수를 넘어서 오류를 발생시킬 수 있음
	- `ConversationBufferWindowMemory` : 슬라이드 윈도우 개념을 적용해 사용자가 지정한 k개의 최근 상호작용(대화쌍) 개수만 저장해 버퍼의 크기를 조절할 수 있지만, 휴리스틱하게 k를 설정할 수 밖에 없으며 여전히 최대 토큰 수를 넘어서 오류를 발생시킬 가능성이 있음
	- `ConversationTokenBufferMemory` : 사용자기 정한 토큰의 수를 넘어가면 정해진 토큰의 수를 넘어서지 않을때까지 오래된 메세지의 앞의 토큰부터 삭제하여 버퍼를 항상 일정한 크기로 유지
	- `ConversationSummaryMemory` : 사용자와 LLM의 상호작용을 요약해 메모리에 저장함으로서 중요한 대화 내용을 포함하면서도 입력 토큰의 크기를 줄일 수 있는 메모리
	- `ConversationSummaryBufferMemory` : 일반적인 `ConversationBufferMemory`처럼 동작하다가 버퍼가 가득차면 해당 버퍼의 메세지 내용들을 요약하고, 이 후의 대화내용들을 다시 버퍼에 저장해 요약내용과 대화내역 두 가지 모두를 API 요청시 사용하는 메모리
	- `Entity Memory` : 필요한 정보를 LLM을 통해 추출하고 key-value의 형태로 저장해 두었다가 필요한 값이 있는 경우 불러와서 사용할 수 있게 해주는 메모리
	- `VectorStore-Backed Memory` : Pinecone, Weaviate과 같은 벡터 저장소와 연동되어 사용자의 쿼리와 연관된 결과값들을 벡터 저장소에 저장하는 메모리
	- 그 외에도 LangChain은 다양한 종류의 메모리를 제공하며 공식문서 참조